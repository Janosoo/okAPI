{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do I get a list of all files that _match_ a particular metadata _property_?\n",
    "\n",
    "### Overview\n",
    "Here we focus on listing all files within a single project that **match** a particular metadata property. One _use-case_ which will benefit greatly from this is:\n",
    "\n",
    " * I have _hundreds_ of files in my project\n",
    " * I want to run a task(s) which only uses _type X_ files\n",
    " * I want to query all _type X_ files with one call\n",
    "\n",
    "Our prior examples of doing this (e.g. the _Organizing files into a Cohort_ cells [here](https://github.com/sbg/okAPI/blob/advanced_access/Tutorials/CGC/batch_SAMtoolsView.ipynb) followed the general strategy of:\n",
    "\n",
    " 1. List all the files (n = _N_)\n",
    " 2. Loop through the list\n",
    " 3. Split off the file extension and see if it's _feasible_\n",
    " 4. Get the metadata of any feasible files (as [here](files_detailOne.ipynb))\n",
    " 5. If the property matches, add it to a _list_ of files to process\n",
    "\n",
    "This works, but will result in up to **_N_+1 API calls**. Here we will show how to do this with only **one API** call and show the speed improvement. If you run this code in the next ten minutes, we'll include the **special bonus** of searching for files using a list of names!\n",
    "\n",
    "### Prerequisites\n",
    " 1. You need your _authentication token_ and the API needs to know about it. See <a href=\"set_AUTH_TOKEN.ipynb\">**set_AUTH_TOKEN.ipynb**</a> for details.\n",
    " 2. You understand how to <a href=\"projects_listAll.ipynb\" target=\"_blank\">list</a> projects you are a member of (we will just use that call directly and pick one here).\n",
    " 3. You have already cloned the Public Project _Cancer Cell Line Encyclopedia (CCLE)_.\n",
    " \n",
    "## Imports\n",
    "We import the _Api_ class from the official sevenbridges-python bindings below. We are also going to grab the time library for crude benchmarking. We are also going to get fancy with future division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sevenbridges as sbg\n",
    "import time as timer\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the object\n",
    "The _Api_ object needs to know your **auth\\_token** and the correct path. Here we assume you are using the .sbgrc file in your home directory. For other options see <a href=\"Setup_API_environment.ipynb\">Setup_API_environment.ipynb</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [USER INPUT] specify platform {cgc, sbpla, etc}\n",
    "prof = 'sbpla'\n",
    "\n",
    "\n",
    "config_file = sbg.Config(profile=prof)\n",
    "api = sbg.Api(config=config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search by metadata\n",
    "This is the **optimal** way to query files matching a particular metadata. Here, we check two (hard-coded) metadata properties. It's possible to check as many as you'd like. We are going to use _Copy of Cancer Cell Line Encyclopedia (CCLE)_ which is a nice big project with **2579** files.\n",
    "\n",
    "#### Notes:\n",
    " * The search by metadata function does **not** work with booleans or integers right now. This is a **known** bug so you **know** we are on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2579 files in your project\n",
      "\n",
      "There are 654 files matching the metadata criteria.\n",
      "This is 25.3586661497 percent of the dataset.\n",
      "Total query time (metadata query method) \n",
      "was 0.383278846741 seconds.\n"
     ]
    }
   ],
   "source": [
    "# [USER INPUT] Set metadata properties and values here; set project name\n",
    "project_name = 'Copy of Cancer Cell Line Encyclopedia (CCLE)'\n",
    "metadata_to_match = {'experimental_strategy': 'WXS',\n",
    "                     'platform':'Illumina'\n",
    "                    }\n",
    "\n",
    "\n",
    "# Find project\n",
    "my_project = [p for p in api.projects.query(limit=100).all()\n",
    "              if p.name == project_name]\n",
    "\n",
    "if not my_project:  #    empty list is False, {list, tuple, etc} is True\n",
    "    print('Target project ({}) not found, please check spelling'.format(project_name))\n",
    "    raise KeyboardInterrupt\n",
    "else:\n",
    "    my_project = my_project[0]\n",
    "    my_project = api.projects.get(id = my_project.id)\n",
    "\n",
    "# How many files do we have?\n",
    "my_files = api.files.query(project = my_project)\n",
    "print('There are {} files in your project'.format(my_files.total))\n",
    "\n",
    "# Query by metadata\n",
    "T0 = timer.time()\n",
    "my_matched_files = api.files.query(\n",
    "    project=my_project, limit=100, \n",
    "    metadata = metadata_to_match)\n",
    " \n",
    "print(\"\"\"\n",
    "There are {} files matching the metadata criteria.\n",
    "This is {} percent of the dataset.\n",
    "Total query time (metadata query method) \n",
    "was {} seconds.\"\"\"\n",
    "      .format(my_matched_files.total,\n",
    "              100*(my_matched_files.total/my_files.total),\n",
    "              timer.time()-T0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through metadata\n",
    "This is very likely the non-optimal approach - please take a look in the mirror and ask yourself \"Do I really need this?\" We are going to mimic the operation above, with a few approximations:\n",
    "\n",
    " * build a list of all the file names\n",
    " * randomly sample 100 of them\n",
    " * search files by **file names**\n",
    " * check the metadata of each file within the list individually\n",
    " * build a matched_file_list for any single file that matches\n",
    " \n",
    "This would let us do things like check for booleans (bug), integers (bug), or **ranges** - none of these are currently possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good news, we have taken 100 random files\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Build list of file names\n",
    "f_names = [f.name for f in my_files.all()]\n",
    "f_total = len(f_names)\n",
    "\n",
    "# Random index of file names to check (only taking 100)\n",
    "some_files = list(np.random.choice(\n",
    "    f_names, size=100, replace=False))\n",
    "\n",
    "# file list of only those 100 files\n",
    "some_of_my_files = api.files.query(\n",
    "    project = my_project, limit = 100,\n",
    "    names = some_files)\n",
    "\n",
    "print('Good news, we have taken {} random files'\n",
    "      .format(some_of_my_files.total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 23 files matching the metadata criteria.\n",
      "This is 23.0 percent of the dataset.\n",
      "Total query time (single file method) \n",
      "was 18.7982280254 seconds.\n"
     ]
    }
   ],
   "source": [
    "keys = metadata_to_match.keys()\n",
    "vals = []\n",
    "for k in keys:\n",
    "    vals.append(metadata_to_match[k])\n",
    "\n",
    "T0 = timer.time()\n",
    "file_list = []\n",
    "\n",
    "for f in some_of_my_files:\n",
    "    single_f = api.files.get(id = f.id)\n",
    "    if single_f.metadata[keys[0]] == vals[0] \\\n",
    "    and single_f.metadata[keys[1]] == vals[1]:\n",
    "        file_list.append(single_f)\n",
    "\n",
    "print(\"\"\"\n",
    "There are {} files matching the metadata criteria.\n",
    "This is {} percent of the dataset.\n",
    "Total query time (single file method) \n",
    "was {} seconds.\"\"\"\n",
    "      .format(len(file_list)+1,\n",
    "              100*((len(file_list)+1)/100),\n",
    "              timer.time()-T0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "There is a _randomness_ here, but running this a few times I've found about a **factor of 40-50x** speed advantage to _including metadata in the query_ rather than _checking files individually_. Keep in mind, only 100 individual files were checked, this would scale **very poorly** if all 2579 files were checked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information\n",
    "Detailed documentation of this particular REST architectural style request is available [here](http://docs.cancergenomicscloud.org/docs/list-files-in-a-project)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
