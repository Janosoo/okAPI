{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I get unavailable metadata\n",
    "This is an **alpha** feature using the SparqQL endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from defs.apimethods import *\n",
    "import SPARQLWrapper as spark\n",
    "import urllib as urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0) Check that sparql endpoint is operational\n",
    "try:\n",
    "    rc = urllib.urlopen(\"https://opensparql.sbgenomics.com\").getcode()\n",
    "except Exception:\n",
    "    rc = 0\n",
    "if rc != 200:\n",
    "    print(\"\"\"script relies on sparql endpoint (https://opensparql.sbgenomics.com/) which is currently not\n",
    "    responding. Can not continue, exiting.\"\"\")\n",
    "    raise KeyboardInterrput\n",
    "\n",
    "# Connect to the endpoint\n",
    "sparql_endpoint = \"https://opensparql.sbgenomics.com/bigdata/namespace/tcga_metadata_kb/sparql\"\n",
    "sparql = spark.SPARQLWrapper(sparql_endpoint)   # Initialize the SparQL wrapper with the endpoint\n",
    "\n",
    "# query non-survivors\n",
    "query = \"\"\"\n",
    "    prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    prefix tcga: <https://www.sbgenomics.com/ontologies/2014/11/tcga#>\n",
    "\n",
    "    select distinct ?case_id ?file_name ?path ?days_to_death ?vital_status\n",
    "    where\n",
    "    {\n",
    "      ?case a tcga:Case .\n",
    "      ?case rdfs:label ?case_id .\n",
    "      ?case tcga:hasDiseaseType ?dt .\n",
    "      ?dt rdfs:label 'Breast Invasive Carcinoma' .\n",
    "\n",
    "      ?case tcga:hasDaysToDeath ?days_to_death .\n",
    "      # ?case tcga:hasDaysToLastFollowUp ?days_to_follow .\n",
    "      ?case tcga:hasVitalStatus ?vs .\n",
    "      ?vs rdfs:label ?vital_status .\n",
    "      ?case tcga:hasFile ?file .\n",
    "      \n",
    "      ?file rdfs:label ?file_name .\n",
    "      ?file tcga:hasStoragePath ?path .\n",
    "      \n",
    "      ?file tcga:hasAccessLevel ?ac .\n",
    "      ?ac rdfs:label 'Open' .\n",
    "      \n",
    "      ?file tcga:hasExperimentalStrategy ?es .\n",
    "      ?es rdfs:label 'RNA-Seq'\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "sparql.setQuery(query)              # Define query on the wrapper\n",
    "sparql.setReturnFormat(spark.JSON)  # We want server to return JSON to use\n",
    "results = sparql.query().convert()  # Convert results to Python object\n",
    "# From results, we grab a list of files - TCGA metadata database returns a list of paths\n",
    "filelist = [result['path']['value'] for result in results['results']['bindings']]\n",
    "uuid_list = [result['case_id']['value'] for result in results['results']['bindings']]\n",
    "vital_list = [result['vital_status']['value'] for result in results['results']['bindings']]\n",
    "day_to_death_list = [result['days_to_death']['value'] for result in results['results']['bindings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'426', u'426', u'426', u'2534', u'2534', u'2534', u'2534', u'2534', u'538', u'538']\n",
      "[u'Dead', u'Dead', u'Dead', u'Dead', u'Dead', u'Dead', u'Dead', u'Dead', u'Dead', u'Dead']\n"
     ]
    }
   ],
   "source": [
    "print(day_to_death_list[0:10])\n",
    "print(vital_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query survivors\n",
    "query = \"\"\"\n",
    "    prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    prefix tcga: <https://www.sbgenomics.com/ontologies/2014/11/tcga#>\n",
    "\n",
    "    select distinct ?case_id ?file_name ?path ?days_to_follow ?vital_status\n",
    "    where\n",
    "    {\n",
    "      ?case a tcga:Case .\n",
    "      ?case rdfs:label ?case_id .\n",
    "      ?case tcga:hasDiseaseType ?dt .\n",
    "      ?dt rdfs:label 'Breast Invasive Carcinoma' .\n",
    "\n",
    "      # ?case tcga:hasDaysToDeath ?days_to_death .\n",
    "      ?case tcga:hasDaysToLastFollowUp ?days_to_follow.\n",
    "      ?case tcga:hasVitalStatus ?vs .\n",
    "      ?vs rdfs:label ?vital_status .\n",
    "      ?case tcga:hasFile ?file .\n",
    "      \n",
    "      ?file rdfs:label ?file_name .\n",
    "      ?file tcga:hasStoragePath ?path .\n",
    "      \n",
    "      ?file tcga:hasAccessLevel ?ac .\n",
    "      ?ac rdfs:label 'Open' .\n",
    "      \n",
    "      ?file tcga:hasExperimentalStrategy ?es .\n",
    "      ?es rdfs:label 'RNA-Seq'\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "sparql.setQuery(query)              # Define query on the wrapper\n",
    "sparql.setReturnFormat(spark.JSON)  # We want server to return JSON to use\n",
    "results = sparql.query().convert()  # Convert results to Python object\n",
    "# From results, we grab a list of files - TCGA metadata database returns a list of paths\n",
    "filelist = [result['path']['value'] for result in results['results']['bindings']]\n",
    "uuid_list = [result['case_id']['value'] for result in results['results']['bindings']]\n",
    "vital_list = [result['vital_status']['value'] for result in results['results']['bindings']]\n",
    "day_to_follow_list = [result['days_to_follow']['value'] for result in results['results']['bindings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'01F50ABF-FC15-446E-9D07-EDEECC545A32', u'01F50ABF-FC15-446E-9D07-EDEECC545A32', u'029CE650-5E5A-4100-8596-CD94300E7EF5', u'029CE650-5E5A-4100-8596-CD94300E7EF5', u'02BBB632-0F7F-439D-B8F0-C86A06237424', u'02BBB632-0F7F-439D-B8F0-C86A06237424', u'02BBB632-0F7F-439D-B8F0-C86A06237424', u'02BBB632-0F7F-439D-B8F0-C86A06237424', u'02BBB632-0F7F-439D-B8F0-C86A06237424', u'02BBB632-0F7F-439D-B8F0-C86A06237424']\n",
      "[u'Alive', u'Alive', u'Alive', u'Alive', u'Alive', u'Alive', u'Alive', u'Alive', u'Alive', u'Alive']\n"
     ]
    }
   ],
   "source": [
    "print(uuid_list[0:10])\n",
    "print(vital_list[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
