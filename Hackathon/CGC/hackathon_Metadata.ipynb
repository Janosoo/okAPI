{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do I summarize metadata _properties_ for all the files that were used in a task?\n",
    "\n",
    "### Overview\n",
    "Here we will build on Gaurav's _Gene Data Munger_ app, which neatly cleans and organizes level 3 gene expression data into a table with dimensions [number_of_genes x number_of_patients]. Here, we will:\n",
    " \n",
    " 1. Query a task that Gaurav ran\n",
    " 2. List all input files to that task\n",
    " 3. Query the metadata for each input file\n",
    " 4. Pass this information back to an tool which makes a table [number_of_properties x number_of_patients] on the platform\n",
    "\n",
    "### Prerequisites\n",
    " 1. You need to be a member (or owner) of _Gaurav's_ project.\n",
    " 2. You need your _authentication token_ and the API needs to know about it. See <a href=\"set_AUTH_TOKEN.ipynb\">**set_AUTH_TOKEN.ipynb**</a> for details.\n",
    " \n",
    "### Imports and Definitions\n",
    "A single call is sufficient to get a file list. We will show two different options, both of which are defined in the apimethods.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from defs.apimethods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all the _files_ and _tasks_ in Gaurav's project\n",
    "We will list all of your files and tasks in Gaurav's project\n",
    "\n",
    "#### PROTIPS\n",
    "* The recipe for _listing projects_ is [here](../../Recipes/CGC/projects_listAll.ipynb)\n",
    "* The recipe for _listing files_ in a project is [here](../../Recipes/CGC/files_listAll.ipynb)\n",
    "* The recipe for _listing tasks_ in a project is [here](../../Recipes/CGC/tasks_listAll.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [USER INPUT]\n",
    "project_name = 'Gene Expression'\n",
    "ind_task = 0      # task to get inputs from\n",
    "\n",
    "# LIST all projects\n",
    "existing_projects = API(path='projects')                              \n",
    "if project_name in existing_projects.name:\n",
    "    p_index = existing_projects.name.index(project_name)\n",
    "else:\n",
    "    print('project does not exist, please check name.')\n",
    "    raise KeyboardInterupt\n",
    "    \n",
    "# LIST all files in the project\n",
    "my_files = API(path='files', query={'project': existing_projects.id[p_index], \\\n",
    "                                   'limit':100})\n",
    "print('There are %i files in project (%s)'\\\n",
    "      % (len(my_files.name),existing_projects.name[p_index]))\n",
    "\n",
    "# LIST all task in the project\n",
    "my_tasks = API(path='tasks', query={'project': existing_projects.id[p_index]})\n",
    "print('There are %i tasks in project (%s)'\\\n",
    "      % (len(my_tasks.name),existing_projects.name[p_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the files that were used for the most recent task\n",
    "We will list all of your files and tasks in Gaurav's project\n",
    "\n",
    "#### PROTIPS\n",
    "* The recipe for getting task inputs is [here](../../Recipes/CGC/tasks_monitorAndGetResults.ipynb)\n",
    "* The recipe for getting the metadata for single files is [here](../../Recipes/CGC/files_detailOne.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DETAIL a single task\n",
    "single_task = API(method='GET', path=('tasks/' + my_tasks.id[ind_task]))\n",
    "\n",
    "# parse out the file names\n",
    "my_input_files = [ii['name'] for ii in single_task.inputs['input_files']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all metadata for the files \n",
    "Now we loop through each of the input files, matching it to the list of all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [USER INPUT] \n",
    "metadata_to_include = [u'aliquot_id', \n",
    "                       u'data_subtype', \n",
    "                       u'case_uuid', \n",
    "                       u'disease_type', \n",
    "                       u'data_type', \n",
    "                       u'gender', \n",
    "                       u'sample_uuid', \n",
    "                       u'sample_id', \n",
    "                       u'investigation', \n",
    "                       u'data_format', \n",
    "                       u'sample_type', \n",
    "                       u'platform', \n",
    "                       u'case_id', \n",
    "                       u'primary_site', \n",
    "                       u'age_at_diagnosis', \n",
    "                       u'race', \n",
    "                       u'vital_status', \n",
    "                       u'experimental_strategy', \n",
    "                       u'ethnicity', \n",
    "                       u'aliquot_uuid']\n",
    "\n",
    "# Initate a metadata dictionary\n",
    "metadata = {metadata_to_include[0] : []}\n",
    "for md in metadata_to_include[1:]:\n",
    "    metadata[md] = []\n",
    "\n",
    "# SINGLE-FILE method\n",
    "for f_name in my_input_files:\n",
    "    f_id = my_files.id[my_files.name.index(f_name)]\n",
    "    single_file = API(path=('files/' + f_id))\n",
    "    keys = single_file.metadata.keys()\n",
    "    for md in metadata_to_include:\n",
    "        if md in keys:\n",
    "            metadata[md].append(single_file.metadata[md])\n",
    "        else:\n",
    "            # Error handling for missing data, is 0 best choice?\n",
    "            metadata[md].append(0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we save these locally?\n",
    "Yes we can! There are already sitting in our Python variables, holding out for a hero - a data scientist hero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put these in a directory\n",
    "dl_dir = 'tables/'\n",
    "try:                    \n",
    "    # make sure we have the download directory\n",
    "    os.stat(dl_dir)\n",
    "except:\n",
    "    os.mkdir(dl_dir)\n",
    "    \n",
    "    \n",
    "# SAVE the index file  \n",
    "f_id = open((dl_dir + 'metadata.txt'), 'w')\n",
    "for md_prop in metadata_to_include:\n",
    "    f_id.write(md_prop + ' \\n')\n",
    "f_id.close()\n",
    "\n",
    "\n",
    "# SAVE individual files\n",
    "for md_prop in metadata_to_include:\n",
    "    f_id = open((dl_dir + md_prop + '_index.txt'), 'w')\n",
    "    \n",
    "    for md in metadata[md_prop]:\n",
    "        if type(md) != str:\n",
    "            f_id.write((str(md) + ' \\n'))\n",
    "        else:\n",
    "            f_id.write((md + ' \\n'))\n",
    "    f_id.close()\n",
    "    \n",
    "    \n",
    "# SAVE one big table\n",
    "f_id = open((dl_dir + 'big_table.txt'), 'w')\n",
    "\n",
    "for md_prop in metadata_to_include:\n",
    "    for md in metadata[md_prop]:\n",
    "        if type(md) != str:\n",
    "            f_id.write((str(md) + ' \\t'))\n",
    "        else:\n",
    "            f_id.write((md + ' \\t'))\n",
    "    f_id.write('\\n')\n",
    "\n",
    "f_id.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a table in a different project\n",
    "Now we need to write this metadata somewhere, what better place than on the CGC?\n",
    "\n",
    "#### PROTIPS\n",
    "* The recipe for getting app inputs is [here](../../Recipes/CGC/apps_detailOne.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [USER INPUT]\n",
    "project_name = 'Keep on Smiling'\n",
    "app_name = 'Table Maker'\n",
    "\n",
    "# LIST all projects\n",
    "existing_projects = API(path='projects')                              \n",
    "if project_name in existing_projects.name:\n",
    "    p_index = existing_projects.name.index(project_name)\n",
    "    my_project = API(path=('projects/'+ existing_projects.id[p_index]))\n",
    "else:\n",
    "    print('Project does not exist, please check name.')\n",
    "    raise KeyboardInterupt\n",
    "    \n",
    "# LIST all apps in the project\n",
    "my_apps = API(path='apps', query={'project': my_project.id, \\\n",
    "                                   'limit':100})\n",
    "print('There are %i apps in project (%s)'\\\n",
    "      % (len(my_apps.name),my_project.name))\n",
    "if app_name in my_apps.name:\n",
    "    a_index = my_apps.name.index(app_name)\n",
    "else:\n",
    "    print('App does not exist, please check name.')\n",
    "    raise KeyboardInterupt\n",
    "    \n",
    "single_app = API(path=('apps/' + my_apps.id[a_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we should do next\n",
    "If I was able to wrap better apps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "single_app.raw['inputs']\n",
    "in_list = [ii['id'][1:] for ii in single_app.raw['inputs']]\n",
    "# print(in_list)\n",
    "\n",
    "new_task = {'description': 'Create a table of metadata, started with hackathon_Metadata.ipynb',\n",
    "            'name': 'Table Maker Run',\n",
    "            'app': (single_app.id),\n",
    "            'project': my_project.id,\n",
    "            'inputs': {\n",
    "                'f_name_out': 'awesome', \n",
    "                'properties': metadata_to_include, \n",
    "                'age_at_diagnosis': metadata['age_at_diagnosis'], \n",
    "                'aliquot_id': metadata['aliquot_id'], \n",
    "                'aliquot_uuid': metadata['aliquot_uuid'], \n",
    "                'case_id': metadata['case_id'], \n",
    "                'case_uuid': metadata['case_uuid'], \n",
    "                'data_format': metadata['data_format'], \n",
    "                'data_subtype': metadata['data_subtype'], \n",
    "                'data_type': metadata['data_type'], \n",
    "                'disease_type': metadata['disease_type'],\n",
    "                'ethnicity': metadata['ethnicity'], \n",
    "                'experimental_strategy': metadata['experimental_strategy'],\n",
    "                'gender': metadata['gender'], \n",
    "                'investigation': metadata['investigation'], \n",
    "                'platform': metadata['platform'], \n",
    "                'primary_site': metadata['primary_site'], \n",
    "                'race': metadata['race'], \n",
    "                'sample_id': metadata['sample_id'], \n",
    "                'sample_type': metadata['sample_type'], \n",
    "                'sample_uuid': metadata['sample_uuid'], \n",
    "                'vital_status': metadata['vital_status']\n",
    "            }\n",
    "}\n",
    "\n",
    "my_task = API(method='POST', data=new_task, path='tasks/', query = {'action': 'run'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
